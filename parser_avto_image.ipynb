{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:47<00:00,  1.25s/it]\n",
      "100%|██████████| 38/38 [00:48<00:00,  1.27s/it]\n",
      "100%|██████████| 38/38 [00:51<00:00,  1.36s/it]\n",
      "100%|██████████| 38/38 [00:50<00:00,  1.33s/it]\n",
      "100%|██████████| 38/38 [00:51<00:00,  1.36s/it]\n",
      "100%|██████████| 38/38 [00:53<00:00,  1.41s/it]\n",
      "100%|██████████| 38/38 [00:55<00:00,  1.47s/it]\n",
      "100%|██████████| 38/38 [00:54<00:00,  1.43s/it]\n",
      "100%|██████████| 38/38 [00:48<00:00,  1.27s/it]\n",
      "100%|██████████| 38/38 [00:50<00:00,  1.32s/it]\n",
      "100%|██████████| 38/38 [00:49<00:00,  1.30s/it]\n",
      "100%|██████████| 37/37 [00:52<00:00,  1.42s/it]\n",
      "100%|██████████| 37/37 [00:52<00:00,  1.41s/it]\n",
      "100%|██████████| 37/37 [00:51<00:00,  1.40s/it]\n",
      "100%|██████████| 37/37 [00:50<00:00,  1.38s/it]\n",
      "100%|██████████| 37/37 [00:53<00:00,  1.45s/it]\n",
      "100%|██████████| 37/37 [00:50<00:00,  1.37s/it]\n",
      "100%|██████████| 37/37 [00:54<00:00,  1.48s/it]\n",
      "100%|██████████| 37/37 [00:53<00:00,  1.44s/it]\n",
      "100%|██████████| 37/37 [00:50<00:00,  1.36s/it]\n",
      "100%|██████████| 37/37 [00:47<00:00,  1.29s/it]\n",
      "100%|██████████| 37/37 [00:51<00:00,  1.38s/it]\n",
      "100%|██████████| 37/37 [00:55<00:00,  1.49s/it]\n",
      "100%|██████████| 37/37 [00:57<00:00,  1.56s/it]\n",
      "100%|██████████| 37/37 [00:52<00:00,  1.43s/it]\n",
      "100%|██████████| 37/37 [00:50<00:00,  1.37s/it]\n",
      "100%|██████████| 37/37 [00:50<00:00,  1.37s/it]\n",
      "100%|██████████| 37/37 [00:50<00:00,  1.36s/it]\n",
      "100%|██████████| 37/37 [00:50<00:00,  1.36s/it]\n",
      "100%|██████████| 37/37 [00:52<00:00,  1.43s/it]\n",
      "100%|██████████| 37/37 [00:52<00:00,  1.43s/it]\n",
      "100%|██████████| 37/37 [00:53<00:00,  1.44s/it]\n",
      "100%|██████████| 37/37 [00:54<00:00,  1.47s/it]\n",
      "100%|██████████| 37/37 [00:53<00:00,  1.43s/it]\n",
      "100%|██████████| 37/37 [00:52<00:00,  1.43s/it]\n",
      "100%|██████████| 37/37 [00:50<00:00,  1.35s/it]\n",
      "100%|██████████| 37/37 [00:48<00:00,  1.31s/it]\n",
      "100%|██████████| 37/37 [00:51<00:00,  1.39s/it]\n",
      "100%|██████████| 37/37 [00:52<00:00,  1.41s/it]\n",
      "100%|██████████| 37/37 [00:53<00:00,  1.45s/it]\n",
      "100%|██████████| 37/37 [00:50<00:00,  1.37s/it]\n",
      "100%|██████████| 37/37 [00:51<00:00,  1.39s/it]\n",
      "100%|██████████| 37/37 [00:49<00:00,  1.34s/it]\n",
      "100%|██████████| 37/37 [00:52<00:00,  1.42s/it]\n",
      "100%|██████████| 37/37 [00:51<00:00,  1.39s/it]\n",
      "100%|██████████| 37/37 [00:53<00:00,  1.44s/it]\n",
      "100%|██████████| 37/37 [00:50<00:00,  1.37s/it]\n",
      "100%|██████████| 37/37 [00:52<00:00,  1.42s/it]\n",
      "100%|██████████| 37/37 [00:50<00:00,  1.37s/it]\n",
      "100%|██████████| 37/37 [00:52<00:00,  1.41s/it]\n",
      "100%|██████████| 37/37 [00:51<00:00,  1.40s/it]\n",
      "100%|██████████| 37/37 [00:50<00:00,  1.37s/it]\n",
      "100%|██████████| 37/37 [00:54<00:00,  1.48s/it]\n",
      "100%|██████████| 37/37 [00:52<00:00,  1.42s/it]\n",
      "100%|██████████| 37/37 [00:49<00:00,  1.33s/it]\n",
      "100%|██████████| 37/37 [00:47<00:00,  1.29s/it]\n",
      "100%|██████████| 37/37 [00:48<00:00,  1.31s/it]\n",
      "100%|██████████| 37/37 [00:54<00:00,  1.46s/it]\n",
      "100%|██████████| 37/37 [00:52<00:00,  1.42s/it]\n",
      "100%|██████████| 37/37 [00:50<00:00,  1.37s/it]\n",
      "100%|██████████| 37/37 [00:52<00:00,  1.42s/it]\n",
      "100%|██████████| 37/37 [00:53<00:00,  1.45s/it]\n",
      "100%|██████████| 37/37 [00:54<00:00,  1.46s/it]\n"
     ]
    }
   ],
   "source": [
    "# Парсил данные по автомобилям сначала по моделям, согранял в отдельные csv, так как на на сайте периодически менялись идентификаторы, \n",
    "# то вынружал кусками, потом это все склеивал, потом пробовал парсить по всем моделям постранично, так как периодически соединение отваливалось, выгружал кусками, \n",
    "# потом все это склеивал в один большой датасет\n",
    "\n",
    "import requests\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "os.chdir(os.path.expanduser(r'~\\Google Диск\\PYTHON\\SkillFactory\\Data Science\\Нейронные сети\\Vaz_2107'))\n",
    "base_url = 'https://auto.ru/cars/vaz/2107/'\n",
    "#base_url = 'https://auto.ru/cars/all/?output_type=table'\n",
    "#page_part = '&page='\n",
    "page_part = 'used/?page='\n",
    "#cars_all = []\n",
    "#df_brand = ['mitsubishi']\n",
    "#for j in df_brand:\n",
    "    #url_gen = \n",
    "for i in range(1, 64):\n",
    "    url_gen = base_url + page_part + str(i)\n",
    "    rt = requests.get(url_gen)\n",
    "    rt.encoding = 'utf-8'\n",
    "    soup = BeautifulSoup(rt.text, 'html.parser')\n",
    "    ads = soup.find_all('div', class_= 'ListingItem')\n",
    "    #.find_all('div', class_='ListingItemWide')\n",
    "    for ur in tqdm(ads):\n",
    "        title_url = ur.find('a', class_='Link ListingItemTitle__link').get('href')\n",
    "        rt = requests.get(title_url)\n",
    "        rt.encoding = 'utf-8'\n",
    "        soup = BeautifulSoup(rt.text, 'html.parser')\n",
    "        try:\n",
    "            ads_1 = soup.find('img', class_='ImageGalleryDesktop__image ImageGalleryDesktop__image_hidden').get('src')\n",
    "           # print(ads_1)\n",
    "        except:\n",
    "            pass\n",
    "            #ads = soup.find('img', class_='ImageGalleryFullscreenVertical__image').get('src')\n",
    "        #else:\n",
    "            #pass\n",
    "           # ads = soup.find('img', class_='ImageGalleryFullscreenVertical__background-image ImageGalleryFullscreenVertical__background-image_prev').get('src')\n",
    "        \n",
    "        #.find_all('img', class_ = 'ImageGalleryFullscreenVertical__image')['src']\n",
    "        #img_src = soup.find('div', class_=\"ImageGalleryFullscreenVertical__images-container\")\n",
    "                    #cars = car.find('img', class_='ImageGalleryDesktop__image ImageGalleryDesktop__image_hidden').get('src')\n",
    "        name = random.randrange(1,100000)\n",
    "        fullname = (str(name)+ '.jpg')\n",
    "    #imgurl = \"https:////avatars.mds.yandex.net/get-autoru-vos/5859529/bcf7da664b28dc0ad9ecfa6a9c1ae275/1200x900n\"\n",
    "        urllib.request.urlretrieve('https:' + ads_1,  os.path.basename(fullname))\n",
    "       # print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1200.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "TARGETS = np.linspace(4, 100, 25)\n",
    "\n",
    "def loss(prediction: float) -> float:\n",
    "    return np.abs(TARGETS - prediction).sum() # find x = argmin_p \n",
    "loss(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.,   8.,  12.,  16.,  20.,  24.,  28.,  32.,  36.,  40.,  44.,\n",
       "        48.,  52.,  56.,  60.,  64.,  68.,  72.,  76.,  80.,  84.,  88.,\n",
       "        92.,  96., 100.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TARGETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "10f61bd8e1c8ddfb738e8c0d54faf1911baa5103b162c9ebf575e3fb9043a2f2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
